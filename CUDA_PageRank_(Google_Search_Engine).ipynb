{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshulk-cmu/CUDA_PageRank/blob/main/CUDA_PageRank_(Google_Search_Engine).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPt9kQPtwzgZ",
        "outputId": "704fb027-b20f-41b6-ee27-40c64930b319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timestamp: 2025-09-28T01:03:28.635306+00:00Z\n",
            "Python: 3.12.11  OS: Linux-6.6.97+-x86_64-with-glibc2.35\n",
            "=== nvidia-smi ===\n",
            "Sun Sep 28 01:03:28 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "=== nvcc --version ===\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "PyTorch: 2.8.0+cu126\n",
            "torch.cuda.is_available: True\n",
            "CUDA device count: 1\n",
            "Current device index: 0\n",
            "Device name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Total memory (GB): 14.74\n",
            "CUDA runtime version (torch): 12.6\n"
          ]
        }
      ],
      "source": [
        "# GPU env check & log (Colab)\n",
        "import os, sys, subprocess, datetime, platform\n",
        "log = []\n",
        "\n",
        "from datetime import datetime, UTC\n",
        "ts = datetime.now(UTC).isoformat()\n",
        "\n",
        "def run(cmd):\n",
        "    try:\n",
        "        out = subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT, text=True)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        out = e.output\n",
        "    return out.strip()\n",
        "\n",
        "log.append(f\"Timestamp: {datetime.now(UTC).isoformat()}Z\")\n",
        "log.append(f\"Python: {sys.version.split()[0]}  OS: {platform.platform()}\")\n",
        "\n",
        "# nvidia-smi\n",
        "log.append(\"=== nvidia-smi ===\")\n",
        "log.append(run(\"nvidia-smi || echo 'nvidia-smi not found'\"))\n",
        "\n",
        "# nvcc\n",
        "log.append(\"=== nvcc --version ===\")\n",
        "log.append(run(\"nvcc --version || echo 'nvcc not found'\"))\n",
        "\n",
        "# PyTorch CUDA\n",
        "try:\n",
        "    import torch\n",
        "    log.append(f\"PyTorch: {torch.__version__}\")\n",
        "    log.append(f\"torch.cuda.is_available: {torch.cuda.is_available()}\")\n",
        "    if torch.cuda.is_available():\n",
        "        i = torch.cuda.current_device()\n",
        "        props = torch.cuda.get_device_properties(i)\n",
        "        gb = props.total_memory / (1024**3)\n",
        "        log.append(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
        "        log.append(f\"Current device index: {i}\")\n",
        "        log.append(f\"Device name: {torch.cuda.get_device_name(i)}\")\n",
        "        log.append(f\"Compute capability: {props.major}.{props.minor}\")\n",
        "        log.append(f\"Total memory (GB): {gb:.2f}\")\n",
        "        log.append(f\"CUDA runtime version (torch): {torch.version.cuda}\")\n",
        "    else:\n",
        "        log.append(\"CUDA not available in this runtime. Enable GPU in Runtime → Change runtime type.\")\n",
        "except Exception as e:\n",
        "    log.append(f\"PyTorch check failed: {e}\")\n",
        "\n",
        "# Print and save\n",
        "text = \"\\n\".join(log)\n",
        "print(text)\n",
        "with open(\"/content/gpu_env_log.txt\", \"w\") as f:\n",
        "    f.write(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkKVtUAzxrqi",
        "outputId": "7c106542-df06-4410-b47d-ae670d2e8e79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/cuda-pagerank/data\n",
            "--2025-09-28 01:04:07--  https://snap.stanford.edu/data/web-Google.txt.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21168784 (20M) [application/x-gzip]\n",
            "Saving to: ‘web-Google.txt.gz’\n",
            "\n",
            "web-Google.txt.gz   100%[===================>]  20.19M  5.21MB/s    in 7.5s    \n",
            "\n",
            "2025-09-28 01:04:16 (2.69 MB/s) - ‘web-Google.txt.gz’ saved [21168784/21168784]\n",
            "\n",
            "# Directed graph (each unordered pair of nodes is saved once): web-Google.txt \n",
            "# Webgraph from the Google programming contest, 2002\n",
            "# Nodes: 875713 Edges: 5105039\n",
            "# FromNodeId\tToNodeId\n",
            "0\t11342\n",
            "5105039\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "!mkdir -p /content/drive/MyDrive/cuda-pagerank/data\n",
        "%cd /content/drive/MyDrive/cuda-pagerank/data\n",
        "\n",
        "# Download SNAP web-Google (directed web graph)\n",
        "!wget -nc https://snap.stanford.edu/data/web-Google.txt.gz\n",
        "!gunzip -kf web-Google.txt.gz\n",
        "\n",
        "# Quick sanity: show first lines and basic counts\n",
        "!head -n 5 web-Google.txt\n",
        "!grep -v '^\\s*#' web-Google.txt | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LJcRGaNx_W_",
        "outputId": "614cf86f-ee7b-4243-c37a-efce41ae79de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"nodes\": 916428,\n",
            "  \"edges\": 5105039,\n",
            "  \"dangling_count\": 176974,\n",
            "  \"sample_row0_len\": 212,\n",
            "  \"saved\": \"/content/drive/MyDrive/cuda-pagerank/prep/in_csr_webGoogle.npz\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Build in-neighbor CSR (rows = dest nodes, cols = source nodes), plus out-degree\n",
        "import numpy as np, os, gzip, io, time, json\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/cuda-pagerank/data/web-Google.txt\"\n",
        "assert os.path.exists(data_path)\n",
        "\n",
        "# 1) read edges (skip '#')\n",
        "src = []\n",
        "dst = []\n",
        "with open(data_path, \"r\") as f:\n",
        "    for line in f:\n",
        "        if line.startswith(\"#\"):\n",
        "            continue\n",
        "        a,b = line.strip().split()\n",
        "        src.append(int(a)); dst.append(int(b))\n",
        "src = np.array(src, dtype=np.int64)\n",
        "dst = np.array(dst, dtype=np.int64)\n",
        "\n",
        "N = int(max(src.max(), dst.max())) + 1\n",
        "M = len(src)\n",
        "\n",
        "# 2) out-degree (for weights 1/outdeg)\n",
        "outdeg = np.bincount(src, minlength=N).astype(np.int64)\n",
        "\n",
        "# 3) in-CSR row_ptr/col_idx/val (val = 1/outdeg(source); dangling nodes => 0 later)\n",
        "row_ptr = np.zeros(N + 1, dtype=np.int64)\n",
        "np.add.at(row_ptr, dst + 1, 1)\n",
        "np.cumsum(row_ptr, out=row_ptr)\n",
        "\n",
        "col_idx = np.empty(M, dtype=np.int64)\n",
        "val = np.empty(M, dtype=np.float64)\n",
        "\n",
        "# fill per row using a cursor\n",
        "cursor = row_ptr[:-1].copy()\n",
        "w = 1.0 / np.maximum(outdeg, 1)  # avoid div-by-zero\n",
        "for s, d in zip(src, dst):\n",
        "    i = cursor[d]\n",
        "    col_idx[i] = s\n",
        "    val[i] = w[s]\n",
        "    cursor[d] = i + 1\n",
        "\n",
        "# optional: sort columns within each row for better coalescing later\n",
        "for r in range(N):\n",
        "    start, end = row_ptr[r], row_ptr[r+1]\n",
        "    if end - start > 1:\n",
        "        idx = np.argsort(col_idx[start:end], kind=\"mergesort\")\n",
        "        col_idx[start:end] = col_idx[start:end][idx]\n",
        "        val[start:end] = val[start:end][idx]\n",
        "\n",
        "# persist\n",
        "outdir = \"/content/drive/MyDrive/cuda-pagerank/prep\"\n",
        "os.makedirs(outdir, exist_ok=True)\n",
        "np.savez_compressed(f\"{outdir}/in_csr_webGoogle.npz\",\n",
        "                    N=N, M=M, row_ptr=row_ptr, col_idx=col_idx, val=val, outdeg=outdeg)\n",
        "\n",
        "# quick log\n",
        "print(json.dumps({\n",
        "    \"nodes\": int(N),\n",
        "    \"edges\": int(M),\n",
        "    \"dangling_count\": int((outdeg==0).sum()),\n",
        "    \"sample_row0_len\": int(row_ptr[1]-row_ptr[0]),\n",
        "    \"saved\": f\"{outdir}/in_csr_webGoogle.npz\"\n",
        "}, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjayqW5xyPeX",
        "outputId": "dfdac9ef-5a4d-4139-9cd1-766415d833d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"N\": 916428,\n",
            "  \"M\": 5105039,\n",
            "  \"iterations\": 62,\n",
            "  \"residual_L1\": 8.729468467677312e-07,\n",
            "  \"rank_sum\": 0.9999999999999994,\n",
            "  \"time_sec\": 218.386\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# CPU PageRank (power method, minimal)\n",
        "import numpy as np, time, json\n",
        "\n",
        "npz = np.load(\"/content/drive/MyDrive/cuda-pagerank/prep/in_csr_webGoogle.npz\", allow_pickle=False)\n",
        "N = int(npz[\"N\"]); M = int(npz[\"M\"])\n",
        "row_ptr = npz[\"row_ptr\"]; col_idx = npz[\"col_idx\"]; val = npz[\"val\"]; outdeg = npz[\"outdeg\"]\n",
        "\n",
        "alpha = 0.85\n",
        "tol = 1e-6\n",
        "max_iter = 200\n",
        "\n",
        "r = np.full(N, 1.0 / N, dtype=np.float64)\n",
        "r_new = np.empty_like(r)\n",
        "\n",
        "dangling_mask = (outdeg == 0)\n",
        "\n",
        "def spmv_pull(row_ptr, col_idx, val, x):\n",
        "    y = np.zeros_like(x)\n",
        "    for i in range(N):\n",
        "        s = 0.0\n",
        "        start, end = row_ptr[i], row_ptr[i+1]\n",
        "        for p in range(start, end):\n",
        "            s += val[p] * x[col_idx[p]]\n",
        "        y[i] = s\n",
        "    return y\n",
        "\n",
        "t0 = time.time()\n",
        "for it in range(1, max_iter + 1):\n",
        "    tmp = spmv_pull(row_ptr, col_idx, val, r)\n",
        "    dangling_mass = r[dangling_mask].sum() / N\n",
        "    r_new[:] = alpha * (tmp + dangling_mass) + (1.0 - alpha) / N\n",
        "    diff = np.abs(r_new - r).sum()\n",
        "    r, r_new = r_new, r\n",
        "    if diff < tol:\n",
        "        break\n",
        "t1 = time.time()\n",
        "\n",
        "print(json.dumps({\n",
        "    \"N\": N, \"M\": M,\n",
        "    \"iterations\": it,\n",
        "    \"residual_L1\": float(diff),\n",
        "    \"rank_sum\": float(r.sum()),\n",
        "    \"time_sec\": round(t1 - t0, 3)\n",
        "}, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save CSR to flat binaries for CUDA C++ (float64 weights)\n",
        "import numpy as np, json, os\n",
        "\n",
        "npz = np.load(\"/content/drive/MyDrive/cuda-pagerank/prep/in_csr_webGoogle.npz\", allow_pickle=False)\n",
        "N = int(npz[\"N\"]); M = int(npz[\"M\"])\n",
        "row_ptr = npz[\"row_ptr\"].astype(np.int64, copy=False)\n",
        "col_idx = npz[\"col_idx\"].astype(np.int64, copy=False)\n",
        "val = npz[\"val\"].astype(np.float64, copy=False)\n",
        "outdeg = npz[\"outdeg\"].astype(np.int64, copy=False)\n",
        "\n",
        "outdir = \"/content/drive/MyDrive/cuda-pagerank/bin\"\n",
        "os.makedirs(outdir, exist_ok=True)\n",
        "\n",
        "row_ptr.tofile(f\"{outdir}/row_ptr.bin\")\n",
        "col_idx.tofile(f\"{outdir}/col_idx.bin\")\n",
        "val.tofile(f\"{outdir}/val.bin\")\n",
        "outdeg.tofile(f\"{outdir}/outdeg.bin\")\n",
        "\n",
        "with open(f\"{outdir}/meta.json\", \"w\") as f:\n",
        "    json.dump({\"N\": N, \"M\": M, \"alpha\": 0.85, \"tol\": 1e-6, \"max_iter\": 200}, f)\n",
        "\n",
        "print(\"Saved:\", outdir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv97El_p3-r-",
        "outputId": "34360d71-75b9-4cf7-dc02-5671baff4562"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/drive/MyDrive/cuda-pagerank/bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write CUDA source with timing + GB/s\n",
        "%%writefile /content/pagerank_pull.cu\n",
        "#include <cstdio>\n",
        "#include <cstdlib>\n",
        "#include <cstdint>\n",
        "#include <vector>\n",
        "#include <fstream>\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/reduce.h>\n",
        "#include <thrust/transform_reduce.h>\n",
        "#include <thrust/transform.h>\n",
        "#include <thrust/functional.h>\n",
        "#include <thrust/iterator/zip_iterator.h>\n",
        "#include <thrust/iterator/counting_iterator.h>\n",
        "#include <thrust/tuple.h>\n",
        "#include <cmath>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "struct AbsDiff {\n",
        "  __host__ __device__ double operator()(const thrust::tuple<double,double>& a) const {\n",
        "    return fabs(thrust::get<0>(a) - thrust::get<1>(a));\n",
        "  }\n",
        "};\n",
        "struct MaskPick {\n",
        "  const int64_t* outdeg;\n",
        "  __host__ __device__ double operator()(const thrust::tuple<double,int64_t>& t) const {\n",
        "    return (thrust::get<1>(t)==0) ? thrust::get<0>(t) : 0.0;\n",
        "  }\n",
        "};\n",
        "\n",
        "__global__ void spmv_pull_kernel(const int64_t* __restrict__ row_ptr,\n",
        "                                 const int64_t* __restrict__ col_idx,\n",
        "                                 const double*  __restrict__ val,\n",
        "                                 const double*  __restrict__ r,\n",
        "                                 double*        __restrict__ tmp,\n",
        "                                 int64_t N){\n",
        "  int64_t i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (i >= N) return;\n",
        "  int64_t s0 = row_ptr[i], s1 = row_ptr[i+1];\n",
        "  double s = 0.0;\n",
        "  for (int64_t p = s0; p < s1; ++p) s += val[p] * r[col_idx[p]];\n",
        "  tmp[i] = s;\n",
        "}\n",
        "\n",
        "__global__ void finalize_kernel(double* __restrict__ r_new,\n",
        "                                const double* __restrict__ tmp,\n",
        "                                double alpha, double d_ave, double base,\n",
        "                                int64_t N){\n",
        "  int64_t i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (i >= N) return;\n",
        "  r_new[i] = alpha * (tmp[i] + d_ave) + base;\n",
        "}\n",
        "\n",
        "static void read_bin(const char* path, void* buf, size_t bytes){\n",
        "  std::ifstream f(path, std::ios::binary);\n",
        "  if(!f){ fprintf(stderr,\"Cannot open %s\\n\", path); std::exit(1); }\n",
        "  f.read(reinterpret_cast<char*>(buf), bytes);\n",
        "  if(!f){ fprintf(stderr,\"Short read on %s\\n\", path); std::exit(1); }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  printf(\"=== CUDA PageRank Implementation ===\\n\");\n",
        "\n",
        "  // tiny JSON parse\n",
        "  printf(\"Loading configuration...\\n\");\n",
        "  std::ifstream mf(\"/content/drive/MyDrive/cuda-pagerank/bin/meta.json\");\n",
        "  std::string s((std::istreambuf_iterator<char>(mf)), std::istreambuf_iterator<char>());\n",
        "  auto getnum=[&](const char* key)->double{\n",
        "    auto k=s.find(key); if(k==std::string::npos) return 0; k=s.find(':',k); auto e=s.find_first_of(\",}\\n\",k+1);\n",
        "    return atof(s.substr(k+1,e-k-1).c_str());\n",
        "  };\n",
        "  int64_t N=(int64_t)getnum(\"\\\"N\\\"\"), M=(int64_t)getnum(\"\\\"M\\\"\");\n",
        "  double alpha=getnum(\"\\\"alpha\\\"\"), tol=getnum(\"\\\"tol\\\"\");\n",
        "  int max_iter=(int)getnum(\"\\\"max_iter\\\"\");\n",
        "\n",
        "  printf(\"Problem Size:\\n\");\n",
        "  printf(\"  Nodes (web pages): %lld\\n\", (long long)N);\n",
        "  printf(\"  Edges (links):     %lld\\n\", (long long)M);\n",
        "  printf(\"  Avg links/page:    %.2f\\n\", (double)M / (double)N);\n",
        "  printf(\"Parameters:\\n\");\n",
        "  printf(\"  Damping factor:    %.3f\\n\", alpha);\n",
        "  printf(\"  Tolerance:         %.1e\\n\", tol);\n",
        "  printf(\"  Max iterations:    %d\\n\", max_iter);\n",
        "  printf(\"\\n\");\n",
        "\n",
        "  // host\n",
        "  printf(\"Loading graph data from disk...\\n\");\n",
        "  cudaEvent_t load_start, load_end;\n",
        "  cudaEventCreate(&load_start); cudaEventCreate(&load_end);\n",
        "  cudaEventRecord(load_start);\n",
        "\n",
        "  std::vector<int64_t> h_row_ptr(N+1), h_col_idx(M), h_outdeg(N);\n",
        "  std::vector<double>  h_val(M);\n",
        "  read_bin(\"/content/drive/MyDrive/cuda-pagerank/bin/row_ptr.bin\", h_row_ptr.data(), (N+1)*sizeof(int64_t));\n",
        "  read_bin(\"/content/drive/MyDrive/cuda-pagerank/bin/col_idx.bin\", h_col_idx.data(), M*sizeof(int64_t));\n",
        "  read_bin(\"/content/drive/MyDrive/cuda-pagerank/bin/val.bin\",     h_val.data(),     M*sizeof(double));\n",
        "  read_bin(\"/content/drive/MyDrive/cuda-pagerank/bin/outdeg.bin\",  h_outdeg.data(),  N*sizeof(int64_t));\n",
        "\n",
        "  // device\n",
        "  printf(\"Transferring data to GPU...\\n\");\n",
        "  thrust::device_vector<int64_t> d_row_ptr = h_row_ptr;\n",
        "  thrust::device_vector<int64_t> d_col_idx = h_col_idx;\n",
        "  thrust::device_vector<int64_t> d_outdeg  = h_outdeg;\n",
        "  thrust::device_vector<double>  d_val     = h_val;\n",
        "  thrust::device_vector<double>  r(N, 1.0/(double)N), r_new(N, 0.0), tmp(N, 0.0);\n",
        "\n",
        "  cudaEventRecord(load_end);\n",
        "  cudaEventSynchronize(load_end);\n",
        "  float load_ms;\n",
        "  cudaEventElapsedTime(&load_ms, load_start, load_end);\n",
        "\n",
        "  // Calculate memory usage\n",
        "  double total_mb = ((N+1 + M + N) * sizeof(int64_t) + M * sizeof(double) + 3*N * sizeof(double)) / (1024.0 * 1024.0);\n",
        "  printf(\"Memory transfer completed in %.1f ms (%.1f MB total)\\n\", load_ms, total_mb);\n",
        "\n",
        "  const int64_t threads = 256;\n",
        "  const int64_t blocks  = (N + threads - 1) / threads;\n",
        "  const double base = (1.0 - alpha) / (double)N;\n",
        "\n",
        "  printf(\"GPU Configuration:\\n\");\n",
        "  printf(\"  Threads per block: %lld\\n\", (long long)threads);\n",
        "  printf(\"  Total blocks:      %lld\\n\", (long long)blocks);\n",
        "  printf(\"\\n\");\n",
        "\n",
        "  auto zip_dang  = thrust::make_zip_iterator(thrust::make_tuple(r.begin(), d_outdeg.begin()));\n",
        "  auto zip_rpair = thrust::make_zip_iterator(thrust::make_tuple(r.begin(), r_new.begin()));\n",
        "\n",
        "  // timing\n",
        "  cudaEvent_t e0,e1; cudaEventCreate(&e0); cudaEventCreate(&e1);\n",
        "  double residual=0.0; int it=0; double ms_total=0.0;\n",
        "\n",
        "  printf(\"Starting PageRank iterations...\\n\");\n",
        "  printf(\"Iter | Residual (L1) | Time (ms) | Status\\n\");\n",
        "  printf(\"-----|---------------|-----------|--------\\n\");\n",
        "\n",
        "  for(it=1; it<=max_iter; ++it){\n",
        "    cudaEventRecord(e0);\n",
        "    spmv_pull_kernel<<<(unsigned)blocks,(unsigned)threads>>>(thrust::raw_pointer_cast(d_row_ptr.data()),\n",
        "                                                             thrust::raw_pointer_cast(d_col_idx.data()),\n",
        "                                                             thrust::raw_pointer_cast(d_val.data()),\n",
        "                                                             thrust::raw_pointer_cast(r.data()),\n",
        "                                                             thrust::raw_pointer_cast(tmp.data()),\n",
        "                                                             N);\n",
        "    cudaDeviceSynchronize();\n",
        "    MaskPick pick{ thrust::raw_pointer_cast(d_outdeg.data()) };\n",
        "    double d_mass = thrust::transform_reduce(zip_dang, zip_dang + N, pick, 0.0, thrust::plus<double>());\n",
        "    double d_ave  = d_mass / (double)N;\n",
        "    finalize_kernel<<<(unsigned)blocks,(unsigned)threads>>>(thrust::raw_pointer_cast(r_new.data()),\n",
        "                                                            thrust::raw_pointer_cast(tmp.data()),\n",
        "                                                            alpha, d_ave, base, N);\n",
        "    cudaDeviceSynchronize();\n",
        "    residual = thrust::transform_reduce(zip_rpair, zip_rpair + N, AbsDiff(), 0.0, thrust::plus<double>());\n",
        "    r.swap(r_new);\n",
        "    cudaEventRecord(e1); cudaEventSynchronize(e1);\n",
        "    float ms=0.0f; cudaEventElapsedTime(&ms,e0,e1);\n",
        "    ms_total += ms;\n",
        "\n",
        "    // Progress logging\n",
        "    if (it == 1 || it % 10 == 0 || residual < tol) {\n",
        "      printf(\"%4d | %12.6e | %8.3f | %s\\n\",\n",
        "             it, residual, ms,\n",
        "             (residual < tol) ? \"CONVERGED\" : \"Running\");\n",
        "    }\n",
        "\n",
        "    if (residual < tol) break;\n",
        "  }\n",
        "\n",
        "  double sum_r = thrust::reduce(r.begin(), r.end(), 0.0, thrust::plus<double>());\n",
        "\n",
        "  printf(\"\\n=== Results Summary ===\\n\");\n",
        "  printf(\"Convergence:       %s after %d iterations\\n\",\n",
        "         (residual < tol) ? \"SUCCESS\" : \"MAX_ITER_REACHED\", it);\n",
        "  printf(\"Final residual:    %.6e\\n\", residual);\n",
        "  printf(\"Rank sum:          %.12f (should be ~1.0)\\n\", sum_r);\n",
        "  printf(\"Total time:        %.3f ms\\n\", ms_total);\n",
        "  printf(\"Avg time/iter:     %.3f ms\\n\", ms_total / it);\n",
        "\n",
        "  // rough bytes/iter: edges*(val+col_idx+r) + nodes*(tmp+r_new+r old ~ 3 doubles)\n",
        "  const double bytes_per_edge = 8.0 + 8.0 + 8.0;   // val + col_idx + r[j]\n",
        "  const double bytes_per_node = 8.0 + 8.0 + 8.0;   // tmp[i] + r_new[i] + r[i]\n",
        "  double ms_per_iter = ms_total / it;\n",
        "  double bytes = (bytes_per_edge * (double)M + bytes_per_node * (double)N);\n",
        "  double gbs   = (bytes / (ms_per_iter/1e3)) / 1e9;\n",
        "\n",
        "  printf(\"Memory bandwidth:  %.2f GB/s\\n\", gbs);\n",
        "  printf(\"\\n\");\n",
        "\n",
        "  // JSON output for programmatic use\n",
        "  printf(\"JSON_RESULT: {\\\"N\\\":%lld,\\\"M\\\":%lld,\\\"iterations\\\":%d,\"\n",
        "         \"\\\"residual_L1\\\":%.12e,\\\"rank_sum\\\":%.15f,\"\n",
        "         \"\\\"ms_per_iter\\\":%.3f,\\\"est_GBps\\\":%.2f,\\\"total_ms\\\":%.3f}\\n\",\n",
        "         (long long)N,(long long)M,it,residual,sum_r,ms_per_iter,gbs,ms_total);\n",
        "\n",
        "  cudaEventDestroy(e0);\n",
        "  cudaEventDestroy(e1);\n",
        "  cudaEventDestroy(load_start);\n",
        "  cudaEventDestroy(load_end);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NSjWzN94CGE",
        "outputId": "6d1261e3-7f29-4720-acc2-67e9652e9b39"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/pagerank_pull.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile for T4 or generic (sm_75 fits T4).\n",
        "!nvcc -O3 -arch=sm_75 /content/pagerank_pull.cu -o /content/pagerank_pull"
      ],
      "metadata": {
        "id": "fHHMDpZ74f_g"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the CUDA binary (reads from /drive/.../bin), prints JSON summary\n",
        "!/content/pagerank_pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYzug0zL4rrP",
        "outputId": "9eae2562-0544-4374-823f-c34c20685b8d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CUDA PageRank Implementation ===\n",
            "Loading configuration...\n",
            "Problem Size:\n",
            "  Nodes (web pages): 916428\n",
            "  Edges (links):     5105039\n",
            "  Avg links/page:    5.57\n",
            "Parameters:\n",
            "  Damping factor:    0.850\n",
            "  Tolerance:         1.0e-06\n",
            "  Max iterations:    200\n",
            "\n",
            "Loading graph data from disk...\n",
            "Transferring data to GPU...\n",
            "Memory transfer completed in 197.7 ms (112.9 MB total)\n",
            "GPU Configuration:\n",
            "  Threads per block: 256\n",
            "  Total blocks:      3580\n",
            "\n",
            "Starting PageRank iterations...\n",
            "Iter | Residual (L1) | Time (ms) | Status\n",
            "-----|---------------|-----------|--------\n",
            "   1 | 8.508467e-01 |    3.668 | Running\n",
            "  10 | 1.329880e-02 |    3.437 | Running\n",
            "  20 | 1.827460e-03 |    3.445 | Running\n",
            "  30 | 3.289641e-04 |    3.402 | Running\n",
            "  40 | 6.311191e-05 |    3.221 | Running\n",
            "  50 | 1.240221e-05 |    3.244 | Running\n",
            "  60 | 2.463703e-06 |    3.294 | Running\n",
            "  66 | 9.360145e-07 |    3.204 | CONVERGED\n",
            "\n",
            "=== Results Summary ===\n",
            "Convergence:       SUCCESS after 66 iterations\n",
            "Final residual:    9.360145e-07\n",
            "Rank sum:          1.000003573978 (should be ~1.0)\n",
            "Total time:        221.915 ms\n",
            "Avg time/iter:     3.362 ms\n",
            "Memory bandwidth:  42.98 GB/s\n",
            "\n",
            "JSON_RESULT: {\"N\":916428,\"M\":5105039,\"iterations\":66,\"residual_L1\":9.360145338941e-07,\"rank_sum\":1.000003573978221,\"ms_per_iter\":3.362,\"est_GBps\":42.98,\"total_ms\":221.915}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyO0br7qZcGNbW52Ul/fq5MV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}